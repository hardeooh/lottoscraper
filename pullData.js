const playwright = require('playwright');

//assign date object to take timestamp for scraping
const dateObject = new Date();
const date = (`0${dateObject.getDate()}`).slice(-2);
const month = (`0${dateObject.getMonth() + 1}`).slice(-2);
const year = dateObject.getFullYear();
const hours = dateObject.getHours();
const minutes = dateObject.getMinutes();
const seconds = dateObject.getSeconds();

//Retrieve game URLs from CAlotto table 
async function getScratcherURL() {
  const browser = await playwright.chromium.launch({
      headless: true // setting this to true will not run the UI
  });
  const page = await browser.newPage();
  await page.goto('https://www.calottery.com/scratchers#endTable');
  await page.waitForSelector('.react-accordion')	
  const hrefs = await page.evaluate(() => {
    return Array.from(document.links).map(item => item.href).filter(item => item.indexOf('$') > -1);
    });
  hrefs.sort()
  const unique_hrefs = hrefs.filter((e,i,a)=> a.indexOf(e) === i)
  await browser.close();
  return unique_hrefs
} 

//Go to each scratcher URL and extract game and odds data
async function extractScratcherData(urlArray) {
  const browser = await playwright.chromium.launch({
      headless: true // setting this to true will not run the UI
  });
  const scrapedData = []
  console.log(urlArray, `${urlArray.length} games found`);
  //Go through URL generated by getURL and count prize rows
  for(let i=0;i<urlArray.length;i++){
    const page = await browser.newPage();
    await page.goto(await urlArray[i]);
    await page.waitForSelector('.footer--icon')	
    const rowCount = await page.locator('table').locator('tr').count();
    console.log(rowCount, `rows being added from ${urlArray[i]}`);
    
    //Push each row data into an array
    for(let i=0;i<rowCount;i++){
      scrapedData.push(
        `${year}-${month}-${date} ${hours}:${minutes}:${seconds}\t${await page.locator('.breadcrumb-item').nth(2).innerText()}\t${await page.locator('h1').innerText()}\t${await page.locator('.scratchers-game-detail__info-price').innerText()}\t${await page.locator('table').locator('tr').nth(i).innerText()}`
      )
    }
  }
  await browser.close();
  console.log(scrapedData, 'pullData')
  return scrapedData
}

function cleanScratcherData(scratcherArray) {
  const nArray = scratcherArray
    .map(data => {
    return data.split('\t')
  })

  for(let i=0;i<nArray.length;i++){
    nArray[i][1] = nArray[i][1].slice(-5,-1)
    nArray[i][3] = nArray[i][3].slice(nArray[i][3].indexOf('$')+1)
    nArray[i][4] = nArray[i][4].slice(nArray[i][4].indexOf('$')+1) 
    const separateString = nArray[i][6].split(' of ')
    nArray[i].push(separateString[1])
    console.log(separateString)
    nArray[i][6] = nArray[i][6].slice(0,nArray[i][6].indexOf(' '))
  }
  console.log(nArray)
  
}

module.exports = { getScratcherURL, extractScratcherData, cleanScratcherData }