const playwright = require('playwright');

//assign date object to take timestamp for scraping
const dateObject = new Date();
const date = (`0${dateObject.getDate()}`).slice(-2);
const month = (`0${dateObject.getMonth() + 1}`).slice(-2);
const year = dateObject.getFullYear();
const hours = dateObject.getHours();
const minutes = dateObject.getMinutes();
const seconds = dateObject.getSeconds();

//Retrieve game URLs from CAlotto table 
async function getScratcherURL() {
  const browser = await playwright.chromium.launch({
      headless: true // setting this to true will not run the UI
  });
  const page = await browser.newPage();
  await page.goto('https://www.calottery.com/scratchers#endTable');
  await page.waitForSelector('.react-accordion')	
  const hrefs = await page.evaluate(() => {
    return Array.from(document.links).map(item => item.href).filter(item => item.indexOf('$') > -1);
    });
  hrefs.sort()
  const unique_hrefs = hrefs.filter((e,i,a)=> a.indexOf(e) === i)
  await browser.close();
  return unique_hrefs
} 

//Go to each scratcher URL and extract game and odds data
async function extractScratcherData(urlArray) {
  const browser = await playwright.chromium.launch({
      headless: true // setting this to true will not run the UI
  });
  const scrapedData = []
  console.log(urlArray, `${urlArray.length} games found`);
  //Go through URL generated by getURL and count prize rows
  for(let i=0;i<urlArray.length;i++){
    const page = await browser.newPage();
    await page.goto(await urlArray[i]);
    await page.waitForSelector('.footer--icon')	
    const rowCount = await page.locator('table').locator('tr').count();
    console.log(rowCount, `rows being added from ${urlArray[i]}`);
    
    //Push each row data into an array
    for(let i=0;i<rowCount;i++){
      scrapedData.push(
        `${year}-${month}-${date} ${hours}:${minutes}:${seconds}\t${await page.locator('h1').innerText()}\t${await page.locator('.scratchers-game-detail__info-price').innerText()}\t${await page.locator('table').locator('tr').nth(i).innerText()}`
      )
    }
  }
  await browser.close();
  return scrapedData
  console.log(scrapedData, 'pullData')
}

function cleanScratcherData

module.exports = { getScratcherURL, extractScratcherData }